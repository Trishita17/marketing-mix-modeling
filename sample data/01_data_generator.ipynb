{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "857134d7-9ed1-4674-ba4e-884e49edde1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import string\n",
    "import builtins\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, DateType\n",
    "from pyspark.sql.functions import to_date, to_timestamp, col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfae1b8f-6c1a-4fc2-8214-46f8ead44d1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Campaign Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbb62307-d1eb-401d-b3b6-6c4b54da9edd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_campaign_results_table(n_campaigns=156):\n",
    "    \"\"\"\n",
    "    Generate sample data for Unity Catalog table: campaign_results\n",
    "    \n",
    "    This table contains:\n",
    "    - Campaign ID (unique identifier)  \n",
    "    - Total spend per campaign\n",
    "    - Test sales (treatment group with marketing)\n",
    "    - Control sales (holdout group without marketing)\n",
    "    - Campaign metadata\n",
    "    \n",
    "    Args:\n",
    "        n_campaigns: Number of campaigns to generate (default: 156 = 3 years weekly)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame ready for Unity Catalog table\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate campaign IDs\n",
    "    campaign_ids = [f\"CAMP_{str(i+1).zfill(4)}\" for i in range(n_campaigns)]\n",
    "    \n",
    "    # Generate time periods (weekly campaigns over 3 years)\n",
    "    start_date = datetime(2021, 1, 4)  # Start on Monday\n",
    "    campaign_dates = [start_date + timedelta(weeks=i) for i in range(n_campaigns)]\n",
    "    \n",
    "    # Generate realistic campaign spends (vary by season and strategy)\n",
    "    base_spend = 50000  # Average weekly spend\n",
    "    seasonal_multipliers = []\n",
    "    \n",
    "    for i, date in enumerate(campaign_dates):\n",
    "        # Seasonal effects\n",
    "        month = date.month\n",
    "        if month in [11, 12]:  # Holiday season\n",
    "            seasonal_mult = 1.8\n",
    "        elif month in [6, 7, 8]:  # Summer campaigns  \n",
    "            seasonal_mult = 1.3\n",
    "        elif month in [1, 9]:  # New Year, Back to School\n",
    "            seasonal_mult = 1.4\n",
    "        else:\n",
    "            seasonal_mult = 1.0\n",
    "            \n",
    "        # Add some random variation\n",
    "        random_mult = np.random.uniform(0.7, 1.4)\n",
    "        seasonal_multipliers.append(seasonal_mult * random_mult)\n",
    "    \n",
    "    total_spends = [base_spend * mult for mult in seasonal_multipliers]\n",
    "    \n",
    "    # Generate control sales (baseline business performance)\n",
    "    # This represents what sales would be WITHOUT marketing\n",
    "    base_control_sales = 75000  # Baseline weekly sales\n",
    "    control_sales = []\n",
    "    \n",
    "    for i, date in enumerate(campaign_dates):\n",
    "        # Trend component (business growing 15% per year)\n",
    "        trend_mult = 1 + (i / 52) * 0.15\n",
    "        \n",
    "        # Seasonal component for control sales\n",
    "        month = date.month\n",
    "        if month in [11, 12]:  # Holiday shopping\n",
    "            seasonal_control = 1.6\n",
    "        elif month in [6, 7]:  # Summer activity\n",
    "            seasonal_control = 1.2  \n",
    "        elif month in [1]:  # January dip\n",
    "            seasonal_control = 0.8\n",
    "        else:\n",
    "            seasonal_control = 1.0\n",
    "            \n",
    "        # Random variation\n",
    "        noise = np.random.normal(1, 0.1)\n",
    "        \n",
    "        control = base_control_sales * trend_mult * seasonal_control * noise\n",
    "        control_sales.append(max(control, 10000))  # Floor at 10K\n",
    "    \n",
    "    # Generate test sales (control + marketing lift)\n",
    "    test_sales = []\n",
    "    \n",
    "    for i in range(n_campaigns):\n",
    "        # Marketing lift depends on spend efficiency\n",
    "        spend = total_spends[i]\n",
    "        control = control_sales[i]\n",
    "        \n",
    "        # Diminishing returns: efficiency decreases with higher spend\n",
    "        spend_efficiency = 0.8 * (spend / 100000) ** -0.3  # Power law\n",
    "        \n",
    "        # Base lift from marketing (varies by period)\n",
    "        base_lift_rate = np.random.uniform(0.15, 0.35)  # 15-35% lift\n",
    "        \n",
    "        # Calculate marketing lift\n",
    "        marketing_lift = spend * spend_efficiency * base_lift_rate / 10000\n",
    "        \n",
    "        # Add some noise to test sales\n",
    "        noise = np.random.normal(1, 0.08)\n",
    "        \n",
    "        test = control + marketing_lift * noise\n",
    "        test_sales.append(test)\n",
    "    \n",
    "    # Generate campaign metadata\n",
    "    campaign_types = np.random.choice(['Brand', 'Performance', 'Hybrid'], \n",
    "                                     size=n_campaigns, \n",
    "                                     p=[0.3, 0.4, 0.3])\n",
    "    regions = np.random.choice(['North', 'South', 'East', 'West', 'National'], \n",
    "                              size=n_campaigns, \n",
    "                              p=[0.15, 0.15, 0.15, 0.15, 0.40])\n",
    "    \n",
    "    # Create the campaign results table\n",
    "    campaign_results_df = pd.DataFrame({\n",
    "        'campaign_id': campaign_ids,\n",
    "        'campaign_week': [d.strftime('%Y-%W') for d in campaign_dates],\n",
    "        'campaign_start_date': [d.strftime('%Y-%m-%d') for d in campaign_dates],  # Convert to string\n",
    "        'campaign_type': campaign_types,\n",
    "        'region': regions,\n",
    "        'total_spend': [float(round(spend, 2)) for spend in total_spends],  # Ensure float\n",
    "        'test_sales': [float(round(sales, 2)) for sales in test_sales],  # Ensure float\n",
    "        'control_sales': [float(round(sales, 2)) for sales in control_sales],  # Ensure float\n",
    "        'created_timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),  # Convert to string\n",
    "        'data_source': 'marketing_experiments'\n",
    "    })\n",
    "    \n",
    "    # Add calculated fields - ensure all are proper numeric types\n",
    "    campaign_results_df['incremental_sales'] = (campaign_results_df['test_sales'] - campaign_results_df['control_sales']).astype(float)\n",
    "    campaign_results_df['lift_percent'] = ((campaign_results_df['incremental_sales'] / campaign_results_df['control_sales']) * 100).round(2).astype(float)\n",
    "    campaign_results_df['roas'] = (campaign_results_df['test_sales'] / campaign_results_df['total_spend']).round(3).astype(float)\n",
    "    campaign_results_df['iroas'] = (campaign_results_df['incremental_sales'] / campaign_results_df['total_spend']).round(3).astype(float)\n",
    "    \n",
    "    return campaign_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e4c75e67-ee37-4dbb-8131-3b589f60495e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Campaign Tactics Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "acfb3e70-5ecc-4676-8e1a-dd9091e7e9cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_campaign_tactics_table(campaign_results_df):\n",
    "    \"\"\"\n",
    "    Generate sample data for Unity Catalog table: campaign_tactics\n",
    "    \n",
    "    This table contains:\n",
    "    - Campaign ID (foreign key to campaign_results)\n",
    "    - Tactic breakdown (video, audio, display, search, social, etc.)\n",
    "    - Spend allocation per tactic\n",
    "    \n",
    "    Args:\n",
    "        campaign_results_df: DataFrame from generate_campaign_results_table()\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame ready for Unity Catalog table\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Define available tactics and their typical characteristics\n",
    "    tactics_info = {\n",
    "        'video': {'min_pct': 0.05, 'max_pct': 0.45, 'weight': 0.25},\n",
    "        'audio': {'min_pct': 0.05, 'max_pct': 0.35, 'weight': 0.15},  \n",
    "        'display': {'min_pct': 0.10, 'max_pct': 0.40, 'weight': 0.20},\n",
    "        'search': {'min_pct': 0.15, 'max_pct': 0.50, 'weight': 0.25},\n",
    "        'social': {'min_pct': 0.05, 'max_pct': 0.30, 'weight': 0.15},\n",
    "        'connected_tv': {'min_pct': 0.00, 'max_pct': 0.25, 'weight': 0.10},\n",
    "        'podcast': {'min_pct': 0.00, 'max_pct': 0.15, 'weight': 0.05},\n",
    "        'influencer': {'min_pct': 0.00, 'max_pct': 0.20, 'weight': 0.08},\n",
    "        'email': {'min_pct': 0.02, 'max_pct': 0.10, 'weight': 0.05},\n",
    "        'direct_mail': {'min_pct': 0.00, 'max_pct': 0.15, 'weight': 0.03}\n",
    "    }\n",
    "    \n",
    "    tactics_data = []\n",
    "    \n",
    "    for _, campaign in campaign_results_df.iterrows():\n",
    "        campaign_id = campaign['campaign_id']\n",
    "        total_spend = campaign['total_spend']\n",
    "        campaign_type = campaign['campaign_type']\n",
    "        \n",
    "        # Adjust tactic mix based on campaign type\n",
    "        if campaign_type == 'Brand':\n",
    "            # Brand campaigns favor video, audio, social\n",
    "            tactics_weights = {'video': 0.35, 'audio': 0.20, 'display': 0.15, 'search': 0.10, \n",
    "                             'social': 0.20, 'connected_tv': 0.15, 'podcast': 0.10, 'influencer': 0.12,\n",
    "                             'email': 0.03, 'direct_mail': 0.05}\n",
    "        elif campaign_type == 'Performance':\n",
    "            # Performance campaigns favor search, display, social\n",
    "            tactics_weights = {'video': 0.15, 'audio': 0.08, 'display': 0.30, 'search': 0.40,\n",
    "                             'social': 0.25, 'connected_tv': 0.05, 'podcast': 0.02, 'influencer': 0.05,\n",
    "                             'email': 0.08, 'direct_mail': 0.02}\n",
    "        else:  # Hybrid\n",
    "            # Balanced approach\n",
    "            tactics_weights = {'video': 0.25, 'audio': 0.15, 'display': 0.25, 'search': 0.25,\n",
    "                             'social': 0.18, 'connected_tv': 0.10, 'podcast': 0.06, 'influencer': 0.08,\n",
    "                             'email': 0.05, 'direct_mail': 0.03}\n",
    "        \n",
    "        # Generate random allocation but weighted by campaign type\n",
    "        selected_tactics = []\n",
    "        \n",
    "        # Always include core tactics\n",
    "        core_tactics = ['video', 'audio', 'display', 'search']\n",
    "        for tactic in core_tactics:\n",
    "            if np.random.random() < 0.9:  # 90% chance to include core tactics\n",
    "                selected_tactics.append(tactic)\n",
    "        \n",
    "        # Randomly add other tactics\n",
    "        other_tactics = ['social', 'connected_tv', 'podcast', 'influencer', 'email', 'direct_mail'] \n",
    "        for tactic in other_tactics:\n",
    "            if np.random.random() < tactics_weights.get(tactic, 0.1):\n",
    "                selected_tactics.append(tactic)\n",
    "        \n",
    "        # Ensure we have at least 3 tactics\n",
    "        if len(selected_tactics) < 3:\n",
    "            remaining = [t for t in tactics_info.keys() if t not in selected_tactics]\n",
    "            remaining = list(remaining)  # Convert to list for numpy\n",
    "            need = min(3 - len(selected_tactics), len(remaining))\n",
    "            if need > 0 and len(remaining) > 0:\n",
    "                additional = np.random.choice(remaining, size=need, replace=False)\n",
    "                selected_tactics.extend(additional)\n",
    "        \n",
    "        # Generate spend allocation\n",
    "        # Use Dirichlet distribution for realistic allocation\n",
    "        alpha_values = [tactics_weights.get(tactic, 0.1) * 10 for tactic in selected_tactics]\n",
    "        \n",
    "        # Ensure we have valid alpha values\n",
    "        alpha_values = [max(val, 0.1) for val in alpha_values]  # Minimum alpha of 0.1\n",
    "        \n",
    "        try:\n",
    "            allocations = np.random.dirichlet(alpha_values)\n",
    "        except ValueError:\n",
    "            # Fallback to simple random allocation if Dirichlet fails\n",
    "            allocations = np.random.random(len(selected_tactics))\n",
    "            allocations = allocations / allocations.sum()  # Normalize to sum to 1\n",
    "        \n",
    "        # Create records for each tactic\n",
    "        for i, tactic in enumerate(selected_tactics):\n",
    "            spend_amount = total_spend * allocations[i]\n",
    "            \n",
    "            tactics_data.append({\n",
    "                'campaign_id': campaign_id,\n",
    "                'tactic': tactic,\n",
    "                'spend_amount': round(spend_amount, 2),\n",
    "                'spend_percentage': round(allocations[i] * 100, 1),\n",
    "                'tactic_category': get_tactic_category(tactic),\n",
    "                'channel_type': get_channel_type(tactic),\n",
    "                'created_timestamp': datetime.now(),\n",
    "                'data_source': 'media_planning'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(tactics_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d075753c-1a9b-4081-8230-feb1fa2613bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_tactic_category(tactic):\n",
    "    \"\"\"Helper function to categorize tactics\"\"\"\n",
    "    categories = {\n",
    "        'video': 'Video',\n",
    "        'audio': 'Audio', \n",
    "        'display': 'Display',\n",
    "        'search': 'Search',\n",
    "        'social': 'Social',\n",
    "        'connected_tv': 'Video',\n",
    "        'podcast': 'Audio',\n",
    "        'influencer': 'Social',\n",
    "        'email': 'Direct',\n",
    "        'direct_mail': 'Direct'\n",
    "    }\n",
    "    return categories.get(tactic, 'Other')\n",
    "\n",
    "def get_channel_type(tactic):\n",
    "    \"\"\"Helper function to classify channel types\"\"\"\n",
    "    digital_tactics = ['video', 'display', 'search', 'social', 'connected_tv', 'podcast', 'email']\n",
    "    return 'Digital' if tactic in digital_tactics else 'Traditional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e59c62a-5842-4030-8e48-587bdd6cb699",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_unity_catalog_ddl():\n",
    "    \"\"\"\n",
    "    Generate DDL statements for Unity Catalog tables\n",
    "    \"\"\"\n",
    "    ddl_statements = \"\"\"\n",
    "-- =====================================================\n",
    "-- Unity Catalog DDL Statements for MMM Sample Data\n",
    "-- =====================================================\n",
    "\n",
    "-- Table 1: Campaign Results (Test vs Control)\n",
    "CREATE OR REPLACE TABLE tadityadb.default.campaign_results (\n",
    "  campaign_id STRING NOT NULL COMMENT 'Unique campaign identifier',\n",
    "  campaign_week STRING COMMENT 'Campaign week in YYYY-WW format',\n",
    "  campaign_start_date DATE COMMENT 'Campaign start date',\n",
    "  campaign_type STRING COMMENT 'Brand, Performance, or Hybrid campaign',\n",
    "  region STRING COMMENT 'Geographic region for campaign',\n",
    "  total_spend DECIMAL(12,2) COMMENT 'Total campaign spend in USD',\n",
    "  test_sales DECIMAL(12,2) COMMENT 'Sales from treatment group (with marketing)',\n",
    "  control_sales DECIMAL(12,2) COMMENT 'Sales from control group (without marketing)',\n",
    "  incremental_sales DECIMAL(12,2) COMMENT 'Test sales - Control sales', \n",
    "  lift_percent DECIMAL(5,2) COMMENT 'Percentage lift vs control group',\n",
    "  roas DECIMAL(8,3) COMMENT 'Return on Ad Spend (test_sales / total_spend)',\n",
    "  iroas DECIMAL(8,3) COMMENT 'Incremental ROAS (incremental_sales / total_spend)',\n",
    "  created_timestamp TIMESTAMP COMMENT 'Record creation timestamp',\n",
    "  data_source STRING COMMENT 'Source system for this data'\n",
    ") \n",
    "USING DELTA \n",
    "PARTITIONED BY (campaign_week)\n",
    "COMMENT 'Campaign performance data with test/control results for MMM analysis';\n",
    "\n",
    "-- Table 2: Campaign Tactics (Spend Breakdown)  \n",
    "CREATE OR REPLACE TABLE tadityadb.default.campaign_tactics (\n",
    "  campaign_id STRING NOT NULL COMMENT 'Foreign key to campaign_results table',\n",
    "  tactic STRING NOT NULL COMMENT 'Marketing tactic (video, audio, display, etc.)',\n",
    "  spend_amount DECIMAL(12,2) COMMENT 'Amount spent on this tactic in USD',\n",
    "  spend_percentage DECIMAL(5,1) COMMENT 'Percentage of total campaign spend',\n",
    "  tactic_category STRING COMMENT 'High-level category (Video, Audio, Display, etc.)',\n",
    "  channel_type STRING COMMENT 'Digital or Traditional channel type',\n",
    "  created_timestamp TIMESTAMP COMMENT 'Record creation timestamp',\n",
    "  data_source STRING COMMENT 'Source system for this data'\n",
    ")\n",
    "USING DELTA\n",
    "COMMENT 'Detailed spend breakdown by marketing tactic for each campaign';\n",
    "\n",
    "-- Create indexes for better query performance\n",
    "--CREATE INDEX idx_campaign_results_date ON your_catalog.mmm_schema.--campaign_results (campaign_start_date);\n",
    "--CREATE INDEX idx_campaign_tactics_id ON your_catalog.mmm_schema.--campaign_tactics (campaign_id);\n",
    "\n",
    "-- =====================================================\n",
    "-- Sample Queries for MMM Analysis\n",
    "-- =====================================================\n",
    "\n",
    "-- Query 1: Basic campaign performance summary\n",
    "SELECT \n",
    "  campaign_week,\n",
    "  COUNT(*) as num_campaigns,\n",
    "  SUM(total_spend) as total_spend,\n",
    "  SUM(incremental_sales) as total_incremental_sales,\n",
    "  AVG(iroas) as avg_iroas,\n",
    "  AVG(lift_percent) as avg_lift_percent\n",
    "FROM tadityadb.default.campaign_results \n",
    "GROUP BY campaign_week\n",
    "ORDER BY campaign_week;\n",
    "\n",
    "-- Query 2: Tactic performance analysis\n",
    "SELECT \n",
    "  t.tactic,\n",
    "  COUNT(DISTINCT t.campaign_id) as num_campaigns,\n",
    "  SUM(t.spend_amount) as total_spend,\n",
    "  SUM(c.incremental_sales) as total_incremental_sales,\n",
    "  SUM(c.incremental_sales) / SUM(t.spend_amount) as avg_iroas\n",
    "FROM tadityadb.default.campaign_tactics t\n",
    "JOIN tadityadb.default.campaign_results c ON t.campaign_id = c.campaign_id\n",
    "GROUP BY t.tactic\n",
    "ORDER BY avg_iroas DESC;\n",
    "\n",
    "-- Query 3: Weekly data for MMM model (pivot tactics to columns)\n",
    "WITH weekly_tactics AS (\n",
    "  SELECT \n",
    "    c.campaign_week,\n",
    "    c.campaign_start_date,\n",
    "    c.incremental_sales,\n",
    "    c.total_spend,\n",
    "    t.tactic,\n",
    "    t.spend_amount\n",
    "  FROM tadityadb.default.campaign_results c\n",
    "  JOIN tadityadb.default.campaign_tactics t ON c.campaign_id = t.campaign_id\n",
    ")\n",
    "SELECT \n",
    "  campaign_week,\n",
    "  campaign_start_date,\n",
    "  SUM(incremental_sales) as response_variable,\n",
    "  SUM(CASE WHEN tactic = 'video' THEN spend_amount ELSE 0 END) as video_spend,\n",
    "  SUM(CASE WHEN tactic = 'audio' THEN spend_amount ELSE 0 END) as audio_spend,\n",
    "  SUM(CASE WHEN tactic = 'display' THEN spend_amount ELSE 0 END) as display_spend,\n",
    "  SUM(CASE WHEN tactic = 'search' THEN spend_amount ELSE 0 END) as search_spend,\n",
    "  SUM(CASE WHEN tactic = 'social' THEN spend_amount ELSE 0 END) as social_spend,\n",
    "  SUM(total_spend) as total_spend\n",
    "FROM weekly_tactics\n",
    "GROUP BY campaign_week, campaign_start_date\n",
    "ORDER BY campaign_start_date;\n",
    "\"\"\"\n",
    "    return ddl_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7191ac20-e3fc-48fb-ac0c-126271a0029a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def create_databricks_loader_notebook():\n",
    "    \"\"\"\n",
    "    Generate Databricks notebook code for loading the sample data\n",
    "    \"\"\"\n",
    "    notebook_code = '''\n",
    "# Databricks notebook source\n",
    "# =====================================================  \n",
    "# MMM Sample Data Loader for Unity Catalog\n",
    "# =====================================================\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Marketing Mix Model - Sample Data Generator\n",
    "# MAGIC \n",
    "# MAGIC This notebook generates realistic sample data for MMM analysis:\n",
    "# MAGIC - **campaign_results**: Test vs Control sales data  \n",
    "# MAGIC - **campaign_tactics**: Spend breakdown by marketing tactic\n",
    "# MAGIC \n",
    "# MAGIC The data includes realistic patterns:\n",
    "# MAGIC - Seasonal effects (holidays, summer)\n",
    "# MAGIC - Diminishing returns in marketing effectiveness\n",
    "# MAGIC - Various marketing tactics (video, audio, display, search, etc.)\n",
    "# MAGIC - Test/control experimental design\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"MMM_Data_Generator\").getOrCreate()\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Step 1: Generate Campaign Results Data\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# [Insert the generate_campaign_results_table function here]\n",
    "# [Insert the generate_campaign_tactics_table function here]  \n",
    "# [Insert helper functions here]\n",
    "\n",
    "# Generate the sample data\n",
    "print(\"Generating campaign results data...\")\n",
    "campaign_results_df = generate_campaign_results_table(156)  # 3 years of weekly data\n",
    "\n",
    "print(\"Generating campaign tactics data...\")\n",
    "campaign_tactics_df = generate_campaign_tactics_table(campaign_results_df)\n",
    "\n",
    "print(f\"Generated {len(campaign_results_df)} campaigns\")\n",
    "print(f\"Generated {len(campaign_tactics_df)} tactic records\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Step 2: Data Quality Checks\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Display sample data\n",
    "print(\"CAMPAIGN RESULTS - First 5 rows:\")\n",
    "display(campaign_results_df.head())\n",
    "\n",
    "print(\"\\\\nCAMPAIGN TACTICS - First 10 rows:\")\n",
    "display(campaign_tactics_df.head(10))\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\\\nCAMPAIGN RESULTS SUMMARY:\")\n",
    "display(campaign_results_df.describe())\n",
    "\n",
    "print(\"\\\\nTACTICS SPEND SUMMARY:\")\n",
    "tactics_summary = campaign_tactics_df.groupby('tactic')['spend_amount'].agg(['count', 'sum', 'mean']).round(2)\n",
    "display(tactics_summary)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md  \n",
    "# MAGIC ### Step 3: Load Data to Unity Catalog\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Convert to Spark DataFrames\n",
    "spark_campaign_results = spark.createDataFrame(campaign_results_df)\n",
    "spark_campaign_tactics = spark.createDataFrame(campaign_tactics_df)\n",
    "\n",
    "# Define your catalog and schema names\n",
    "CATALOG_NAME = \"your_catalog\"  # Change this to your catalog\n",
    "SCHEMA_NAME = \"mmm_schema\"     # Change this to your schema\n",
    "\n",
    "# Write to Unity Catalog tables\n",
    "print(\"Writing campaign_results to Unity Catalog...\")\n",
    "(spark_campaign_results\n",
    " .write\n",
    " .mode(\"overwrite\")\n",
    " .option(\"mergeSchema\", \"true\")  \n",
    " .saveAsTable(f\"{CATALOG_NAME}.{SCHEMA_NAME}.campaign_results\"))\n",
    "\n",
    "print(\"Writing campaign_tactics to Unity Catalog...\")\n",
    "(spark_campaign_tactics\n",
    " .write\n",
    " .mode(\"overwrite\") \n",
    " .option(\"mergeSchema\", \"true\")\n",
    " .saveAsTable(f\"{CATALOG_NAME}.{SCHEMA_NAME}.campaign_tactics\"))\n",
    "\n",
    "print(\"✅ Data successfully loaded to Unity Catalog!\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Step 4: Validate Data in Unity Catalog\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Query the tables to validate\n",
    "print(\"Validating campaign_results table:\")\n",
    "results_count = spark.sql(f\"SELECT COUNT(*) as count FROM {CATALOG_NAME}.{SCHEMA_NAME}.campaign_results\").collect()[0]['count']\n",
    "print(f\"Total campaigns: {results_count}\")\n",
    "\n",
    "print(\"\\\\nValidating campaign_tactics table:\")  \n",
    "tactics_count = spark.sql(f\"SELECT COUNT(*) as count FROM {CATALOG_NAME}.{SCHEMA_NAME}.campaign_tactics\").collect()[0]['count']\n",
    "print(f\"Total tactic records: {tactics_count}\")\n",
    "\n",
    "print(\"\\\\nTactic breakdown:\")\n",
    "tactic_breakdown = spark.sql(f\"\"\"\n",
    "SELECT tactic, COUNT(*) as campaigns, ROUND(SUM(spend_amount), 2) as total_spend\n",
    "FROM {CATALOG_NAME}.{SCHEMA_NAME}.campaign_tactics \n",
    "GROUP BY tactic \n",
    "ORDER BY total_spend DESC\n",
    "\"\"\")\n",
    "display(tactic_breakdown)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Step 5: Create MMM Analysis View\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Create a view that pivots tactics for MMM analysis\n",
    "mmm_view_sql = f\"\"\"\n",
    "CREATE OR REPLACE VIEW {CATALOG_NAME}.{SCHEMA_NAME}.mmm_weekly_data AS\n",
    "WITH weekly_tactics AS (\n",
    "  SELECT \n",
    "    c.campaign_week,\n",
    "    c.campaign_start_date,\n",
    "    c.incremental_sales as response_variable,\n",
    "    c.total_spend,\n",
    "    c.lift_percent,\n",
    "    c.iroas,\n",
    "    t.tactic,\n",
    "    t.spend_amount\n",
    "  FROM {CATALOG_NAME}.{SCHEMA_NAME}.campaign_results c\n",
    "  JOIN {CATALOG_NAME}.{SCHEMA_NAME}.campaign_tactics t ON c.campaign_id = t.campaign_id\n",
    ")\n",
    "SELECT \n",
    "  campaign_week,\n",
    "  campaign_start_date,\n",
    "  SUM(response_variable) as incremental_sales,\n",
    "  SUM(CASE WHEN tactic = 'video' THEN spend_amount ELSE 0 END) as video_spend,\n",
    "  SUM(CASE WHEN tactic = 'audio' THEN spend_amount ELSE 0 END) as audio_spend,\n",
    "  SUM(CASE WHEN tactic = 'display' THEN spend_amount ELSE 0 END) as display_spend,\n",
    "  SUM(CASE WHEN tactic = 'search' THEN spend_amount ELSE 0 END) as search_spend,\n",
    "  SUM(CASE WHEN tactic = 'social' THEN spend_amount ELSE 0 END) as social_spend,\n",
    "  SUM(CASE WHEN tactic = 'connected_tv' THEN spend_amount ELSE 0 END) as connected_tv_spend,\n",
    "  SUM(total_spend) as total_spend\n",
    "FROM weekly_tactics\n",
    "GROUP BY campaign_week, campaign_start_date\n",
    "ORDER BY campaign_start_date\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(mmm_view_sql)\n",
    "print(\"✅ MMM analysis view created!\")\n",
    "\n",
    "# Display the view\n",
    "print(\"\\\\nMMM Weekly Data (first 10 rows):\")\n",
    "display(spark.sql(f\"SELECT * FROM {CATALOG_NAME}.{SCHEMA_NAME}.mmm_weekly_data LIMIT 10\"))\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ### Ready for MMM Analysis! 🚀\n",
    "# MAGIC \n",
    "# MAGIC Your data is now ready in Unity Catalog. Use this query to pull data for MMM:\n",
    "# MAGIC \n",
    "# MAGIC ```sql\n",
    "# MAGIC SELECT * FROM your_catalog.mmm_schema.mmm_weekly_data\n",
    "# MAGIC ORDER BY campaign_start_date\n",
    "# MAGIC ```\n",
    "'''\n",
    "    return notebook_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "039333e0-feb8-4d2d-96a7-8c338ba80a7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Marketing Mix Model - Unity Catalog Sample Data Generator\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    print(\"\\\\n1. Generating Campaign Results Data...\")\n",
    "    campaign_results = generate_campaign_results_table(156)  # 3 years weekly\n",
    "    \n",
    "    print(\"\\\\n2. Generating Campaign Tactics Data...\")\n",
    "    campaign_tactics = generate_campaign_tactics_table(campaign_results)\n",
    "    \n",
    "    print(f\"\\\\n📊 DATA SUMMARY:\")\n",
    "    print(f\"   • Total Campaigns: {len(campaign_results)}\")\n",
    "    print(f\"   • Total Tactic Records: {len(campaign_tactics)}\")\n",
    "    print(f\"   • Date Range: {campaign_results['campaign_start_date'].min()} to {campaign_results['campaign_start_date'].max()}\")\n",
    "    print(f\"   • Total Spend: ${campaign_results['total_spend'].sum():,.2f}\")\n",
    "    print(f\"   • Average iROAS: {campaign_results['iroas'].mean():.2f}\")\n",
    "    \n",
    "    print(f\"\\\\n📈 CAMPAIGN RESULTS SAMPLE:\")\n",
    "    print(campaign_results[['campaign_id', 'campaign_week', 'total_spend', 'test_sales', 'control_sales', 'incremental_sales', 'iroas']].head(10))\n",
    "    \n",
    "    print(f\"\\\\n📊 TACTICS BREAKDOWN:\")\n",
    "    tactics_summary = campaign_tactics.groupby('tactic').agg({\n",
    "        'spend_amount': ['count', 'sum', 'mean']\n",
    "    }).round(2)\n",
    "    tactics_summary.columns = ['Campaigns', 'Total_Spend', 'Avg_Spend']\n",
    "    print(tactics_summary.sort_values('Total_Spend', ascending=False))\n",
    "    \n",
    "    print(f\"\\\\n🗄️  UNITY CATALOG DDL:\")\n",
    "    print(\"Use this DDL to create your tables:\")\n",
    "    ddl = create_unity_catalog_ddl()\n",
    "    print(ddl)\n",
    "    \n",
    "    print(f\"\\\\n💻 DATABRICKS NOTEBOOK:\")  \n",
    "    print(\"Copy this code into a Databricks notebook to load your data:\")\n",
    "    notebook = create_databricks_loader_notebook()\n",
    "    \n",
    "    # Save files for easy access\n",
    "    campaign_results.to_csv('campaign_results_sample.csv', index=False)\n",
    "    campaign_tactics.to_csv('campaign_tactics_sample.csv', index=False)\n",
    "    \n",
    "    with open('unity_catalog_ddl.sql', 'w') as f:\n",
    "        f.write(ddl)\n",
    "        \n",
    "    with open('databricks_loader_notebook.py', 'w') as f:\n",
    "        f.write(notebook)\n",
    "    \n",
    "    print(f\"\\\\n✅ FILES CREATED:\")\n",
    "    print(f\"   • campaign_results_sample.csv\")  \n",
    "    print(f\"   • campaign_tactics_sample.csv\")\n",
    "    print(f\"   • unity_catalog_ddl.sql\")\n",
    "    print(f\"   • databricks_loader_notebook.py\")\n",
    "    \n",
    "    print(f\"\\\\n🚀 NEXT STEPS:\")\n",
    "    print(f\"   1. Update catalog/schema names in the DDL\")\n",
    "    print(f\"   2. Run the DDL in Databricks to create tables\") \n",
    "    print(f\"   3. Use the notebook code to load sample data\")\n",
    "    print(f\"   4. Query: SELECT * FROM your_catalog.mmm_schema.mmm_weekly_data\")\n",
    "    print(f\"   5. Calculate response = incremental_sales and run your MMM!\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_data_generator",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
